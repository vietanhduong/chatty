[general]
# Default welcome message
hello_message = "Hello! How can I help you? ðŸ˜Š"
# Show usage statistics when ever a chat completion completed
show_usage = false
# Verbose info in starting up. This different from the log level
# and will only print in the beginning to stderr.
verbose = false
# The percentage of the screen width to use for the bubble width
# Can't be more than 95% and less than 50%
bubble_width_percent = 60

[log]
# Default log level is "info"
level = "info"

# Set log level for specific modules
# e.g: filters = [{ module = "chatty::backend", level = "trace" }]
filters = []

[log.file]
# You can use env var to set the path e.g: $HOME/chatty.log
path = "/tmp/chatty.log"
append = false

# Theme settings
[theme]
name = "base16-ocean.dark"
folder_path = ""

[context.compression]
enabled = false
# The maximum number of tokens in the context before trigger compression
max_tokens = 65_536
# The maximum number of messages in conversation before trigger compression
max_messages = 50
# The number of latest messages to keep in the context
keep_n_messages = 10

[context.truncation]
enabled = false
# If the total no. tokens in the current context is greater than
# context.truncation.max_tokens + backend.connections.max_output_tokens
# then the context will be truncated to fit the limit
max_tokens = 65_536

[backend]
default_model = ""

# At least one backend connection must be enabled
#[[backend.connections]]
#enabled = false
#alias = "OpenAI"
#kind = "openai"    # openai or gemini
#max_output_tokens = None
#endpoint = ""
#api_key = ""

[storage.sqlite]
# Leave it empty to use in-memory database
#path = ""
